---
linkTitle: 12-17-Daily
title: 12-17-Daily AI News Daily
weight: 15
breadcrumbs: false
comments: true
description: Alibaba's Tongyi Wanxiang âœ¨ gets another upgrade.
---
## AI News Daily: December 17, 2025

> `AI News` | `Daily Briefing` | `Web-Wide Data Aggregation` | `Frontier Science Exploration` | `Industry Voices` | `Open-Source Innovation` | `AI & Humanity's Future` | [Visit Web Version â†—ï¸](https://ai.hubtoday.app/) | [Join Our Group Chat](https://source.hubtoday.app/logo/wechat-qun.jpg)

### **Today's Summary**

```
Alibaba's Wan2.6 model now supports 15-second role-playing videos with native audio-visual sync.
Nvidia has launched its Nemotron3 series Nano model, boasting 3 billion parameters and a 4x throughput boost.
ChatGPT introduces a branch chat feature, enabling multi-threaded conversations to prevent information loss.
Peking University's team uncovered a delicate balance phenomenon in LLM content generation via potential functions.
DeepSeek and Qwen are tied at the top of open-source model rankings, with over half of the top models from Chinese teams.
```

### Product & Feature Updates

1.  **Alibaba's Tongyi Wanxiang âœ¨ gets another upgrade.**
    Alibaba has rolled out its [Wan 2.6 Video and Image Model](https://www.xiaohu.ai/c/xiaohu-ai/wan-2-6), making it the first in China to support ğŸš€ role-playing functionality. Users can now create videos up to **15 seconds** long, complete with native audio-visual synchronization and custom audio capabilities. The update also brings new features like scene-level control, multi-person shooting, and **significantly improved instruction following**. This means text-to-image generation precisely captures style details, perfect for short drama production. <br/>![AI News: Tongyi Wanxiang Wan2.6 Video Model Multi-Lens Scene Control Interface](https://source.hubtoday.app/images/2025/12/news_01kckzvawxew3r0sx7yfzjfmng.avif)<br/>

2.  **Nvidia launches its Nemotron 3 Series.**
    The Nemotron 3 series from Nvidia includes three ğŸ”¥ open-source models: **Nano (with 30 billion parameters)**, Super, and Ultra. These models utilize a Mamba-Transformer hybrid MoE architecture. Specifically, the Nemotron 3 Nano [activates with just 3.2 billion parameters](https://www.jiqizhixin.com/articles/2025-12-16-7), yet it boasts a **4x throughput improvement** over its predecessor and supports millions of tokens in context. You can grab it now on [Hugging Face](https://huggingface.co/nvidia), which comes bundled with the 3-trillion-token training dataset, Taobao-MM, and the NeMo Gym reinforcement learning library.

3.  **ChatGPT introduces a new branch chat feature. ğŸ’¬**
    OpenAI has rolled out its ğŸ¨ branch conversation feature on both iOS and Android. This cool new tool lets users create multiple parallel conversation branches, allowing them to [explore new directions based on the original discussion](https://www.aibase.com/zh/news/23721). It's perfect for multi-threaded scenarios like business strategy and creative writing, helping to prevent information from getting lost in linear conversations and boosting ğŸ’¡ overall interactivity and creativity. <br/>![AI News: ChatGPT Branch Chat Feature Operation Interface Screenshot](https://source.hubtoday.app/images/2025/12/news_01kckzvessekt9jxja6f6mv706.avif)<br/>

4.  **Kwai's KAT-Coder-Pro V1 tops the charts! ğŸ†**
    Kwai's Agentic Coding model, [KAT-Coder-Pro V1](https://www.aibase.com/zh/news/23729), just scored a whopping **64 points** ğŸš€ in Artificial Analysis's evaluation, pushing it past Claude 4.5 Sonnet into the overall Top 10! Not only that, it snagged the **#1 spot** in the non-reasoning model leaderboard. This model also consumes significantly fewer tokens than competitors with similar performance, offering serious bang for your buck.

5.  **Gemini now features image tagging! ğŸ·ï¸**
    Google Gemini now lets you ğŸ¨ add text and draw lines as tags when uploading images, giving you precise control over object placement and content modifications. Once you're done, [all annotations are automatically removed](https://m.okjike.com/originalPosts/6941226b36c01015fac9979b), with a handy general prompt: "Modify according to tags, delete tags." This dramatically boosts image editing ğŸ’¡ precision. <br/>![AI News: Gemini Image Tagging Feature Operation Demo Interface](https://source.hubtoday.app/images/2025/12/news_01kckzvmj3e50vr77yws99xq4d.avif)<br/>

### Frontier Research

1.  **Peking University Physics Department reveals LLM dynamics. ğŸ”¬**
    A team from Peking University's School of Physics has, for the first time, uncovered a **delicate balance phenomenon** ğŸ”¥ in LLM generation, leveraging the [Principle of Least Action](https://www.jiqizhixin.com/articles/2025-12-16-8). Their research indicates that LLMs generate content by implicitly learning potential functions rather than strict rule sets, behaving much like thermodynamic equilibrium systems. Interestingly, Claude-4 tends to converge quickly, while GPT-5 Nano prefers exploring the state space. This groundbreaking theory elevates AI research from what was once "alchemy" to a ğŸ’¡ quantifiable science.

2.  **Harvard analyzes Perplexity usage data. ğŸ“Š**
    [Harvard research](https://www.reddit.com/r/artificial/comments/1pnf368/its_been_a_big_week_for_agentic_ai_here_are_10/), based on hundreds of millions of queries, reveals some interesting insights into Perplexity usage. It shows that **55% of users are for personal use**, with 30% for professional scenarios. Productivity/workflow makes up a solid **36%** ğŸš€ of queries, while learning and research account for 21%. Over time, users are shifting from simple tasks to more complex ones, painting a true picture of how Agents are being used.

3.  **Stanford unveils a multimodal DiffFusion framework. ğŸ’¡**
    This new framework leverages diffusion models to achieve [3D Object Detection in Adverse Weather](https://arxiv.org/abs/2512.13107) â˜”. Diffusion-IR tackles image repair, PCR compensates LiDAR data, and the BAFAM module handles dynamic multimodal fusion and bidirectional BEV alignment. It's showcased **optimal robustness** across three major public datasets ğŸ¤–, with zero-shot testing impressively demonstrating its generalization capability.

4.  **New research on Causal LLMs for text classification. ğŸ“‘**
    This [research comparison](https://arxiv.org/abs/2512.12677) delves into two fine-tuning strategies: embedded and instructive. The embedded method, combining 4-bit quantization and LoRA, was used to train an 8B parameter model on a single GPU, yielding significantly better F1 scores than the instructive method ğŸš€. Its performance even outshines domain-specific models like BERT on proprietary datasets and the WIPO-Alpha multi-label task.

5.  **Google Cloud unveils AlphaEvolve. ğŸš€**
    AlphaEvolve, a [Gemini-driven coding agent](https://www.reddit.com/r/artificial/comments/1pnf368/its_been_a_big_week_for_agentic_ai_here_are_10/) ğŸ”¥, is Google Cloud's latest offering, specifically focused on advanced algorithm design. It uses LLMs to suggest code modifications, with a feedback loop designed to evolve algorithm efficiency ğŸ’¡. Currently in private preview, it promises to significantly boost code quality.

### Industry Outlook & Social Impact

1.  **OpenAI and Anthropic establish a new foundation. ğŸ¤**
    OpenAI, Anthropic, and Block have teamed up to establish the [Agentic AI Foundation](https://www.reddit.com/r/artificial/comments/1pnf368/its_been_a_big_week_for_agentic_ai_here_are_10/) ğŸš€ under the Linux Foundation. Their mission? To focus on building interoperability standards for Agents. Generous donations are backing a secure and reliable Agent ecosystem that works across various tools and repositories, with industry leaders all aligning on this key direction for Agent interoperability.

2.  **Stripe launches its Agentic Commerce Suite. ğŸ›ï¸**
    Stripe's [new service](https://www.reddit.com/r/artificial/comments/1pnf368/its_been_a_big_week_for_agentic_ai_here_are_10/) empowers businesses to sell to multiple AI Agents via a single integration ğŸ¯. This comprehensive suite covers everything from product discovery and Agent checkout to payments and fraud detection, all centrally manageable from the Stripe Dashboard ğŸ’¡. This marks the official commercialization of AI-native commerce infrastructure, fully compatible with existing commerce stacks.

3.  **CAICT launches CAIVD Professional Database. ğŸ”’**
    Under the guidance of the Ministry of Industry and Information Technology, the [CAIVD AI Security Vulnerability Database](https://www.aibase.com/zh/news/23731) ğŸ”’ is now officially operational. This database is the sixth addition to the "1 general + 5 professional databases" system, dedicated to collecting and verifying vulnerabilities in AI products. It aims to establish a ğŸš€ collaborative network among product providers, manufacturers, research institutions, and users, standardizing vulnerability disclosure channels. You can access it at: ai.nvdb.org.cn

4.  **Domestic open-source models tie for first place! ğŸ¥‡**
    According to AI researcher Nathan Lambert's [open-source large model leaderboard](https://www.aibase.com/zh/news/23705), DeepSeek, Qwen, and Kimi have been rated as **tied for first place** ğŸ† in terms of influence. This leaderboard features 35 institutions, with over half being Chinese teams! DeepSeek R1 has even surpassed top closed-source models, Qwen has spawned dozens of cross-domain versions ğŸ’¡, and Kimi has made waves by launching the world's first trillion-parameter open-source model. <br/>![AI News: Top Ten Open-Source AI Model Influence Ranking](https://source.hubtoday.app/images/2025/12/news_01kckzvrwkf67sqa5v0339dfy7.avif)<br/>

5.  **Former CIA official brings up remote control tools again. ğŸ•µï¸â€â™‚ï¸**
    Former CIA official Kiriakou claims in a [LADbible video](https://newshacker.me/story?id=46276875) that intelligence agencies can remotely control phones, TVs, and cars ğŸ”’. However, discussions on Hacker News quickly pointed out that this is merely a reiteration of the 2017 Vault 7 leak, not fresh evidence. Commenters questioned Kiriakou's technical relevance and the media's tendency towards sensationalism ğŸ’¡, advising the public to refer to the original leaked documents instead of personal statements.

### Open Source TOP Projects

1.  **ConvertX: A self-hosted file converter. âš™ï¸**
    [ConvertX](https://github.com/C4illin/ConvertX) is a fantastic self-hosted file converter that supports **1000+ formats** ğŸ’¾. It's super compact, requires no third-party services ğŸš€, and is perfect for individuals and businesses looking to set up their private file conversion platform. It's already garnered a solid **â­11.2k** stars!

2.  **MDN Web Docs content repository. ğŸ“š**
    The [MDN Content Repository](https://github.com/mdn/content) is the official source code hub ğŸ“š for MDN Web Docs, boasting over **14,000 pages** of HTML, CSS, JS, HTTP, and Web API documentation. Developers can jump in and contribute content directly ğŸ’¡, and it's already racked up **â­10.2k** stars!

3.  **hashcards: A plain text spaced repetition system. ğŸ“**
    [hashcards](https://github.com/eudoxia0/hashcards) is a super handy ğŸ´ plain text-based spaced repetition learning tool. It's a breeze to set up, requiring no complex configuration, and supports Markdown-formatted cards ğŸš€ for lightweight deployment. It's already caught the eye of many, with **â­629** stars!

4.  **SPEC-AGENTS: A specification-driven development framework. ğŸ› ï¸**
    [SPEC-AGENTS](https://m.okjike.com/originalPosts/69412979d124ce959a40884a) is a zero-configuration ğŸ› ï¸, specification-driven development tool. It facilitates development through natural language communication, breaking it down into distinct stages ğŸ’¡. Plus, it supports switching between multiple programming tools without losing progress. Its documentation-driven workflow ensures a traceable, closed-loop process, empowering even regular users to enjoy a mature software development experience.

5.  **Nvidia acquires SchedMD and doubles down on open source. ğŸ¤**
    Nvidia has acquired [Slurm lead developer SchedMD](https://www.aibase.com/zh/news/23722) ğŸ”¥, promising to maintain its open-source, neutral operation. Slurm itself is a **benchmark** workload management system ğŸ’¡ in the high-performance computing and AI sectors. Nvidia also concurrently released the Alpamayo-R1 inference vision model and the Cosmos world model under permissive licenses, strategically building out its physical AI ecosystem.

### Social Media Shares

1.  **Observation: Alibaba's agentification efforts. ğŸ§**
    A recent [community discussion](https://m.okjike.com/originalPosts/6941451728fa6ac7346dfd22) highlights that Ant Group products are the most aggressive in agentification ğŸš€ because their tool-centric nature prioritizes results over process. Taobao's agentification, however, needs to balance "entry point" advertising revenue ğŸ’¡, while WeChat's enthusiasm for agentification is lower due to its reliance on "usage process" interaction. Users suggest this isn't strategic restraint, but rather a limitation imposed by their commercial models.

2.  **The ironic automation of AI supervision. ğŸ­**
    A [1983 paper](https://x.com/dotey/status/2000796152921293156) eerily predicted automation problems that are now surfacing with AI Agents ğŸ”¥, including skill degradation, memory extraction dilemmas, and monitoring fatigue. The paper underscores that training can't replace real-world experience ğŸ’¡, and humans struggle to stay vigilant when AI makes mistakes. The absolute worst part? The AI interface is dubbed "the worst anomaly detection design," with fatal errors often hidden within verbose text.

3.  **Claude Code's new confirmation mechanism. âœ…**
    A [user's share](https://x.com/hongming731/status/2000727149750427898) highlights how comfortable the interactive experience of Claude Code's new version confirmation mechanism is ğŸ¨. Before executing, the agent presents a detailed operation preview, allowing users to review and confirm each item ğŸ’¡, which is super helpful in preventing accidental modifications. <br/>![AI News: Claude Code Confirmation Mechanism Operation Interface Preview Screenshot](https://source.hubtoday.app/images/2025/12/news_01kckzw3pse4xsm09bvt7x2e6n.avif)<br/>

4.  **AGI discussions shouldn't be dismissed as sci-fi. ğŸ§ **
    A recent [Reddit discussion](https://www.reddit.com/r/artificial/comments/1po1393/dismissing_discussion_of_agi_as_science_fiction/) argues that writing off AGI discussions as mere "science fiction" is "completely unserious" ğŸ”¥. Even skeptical experts believe AGI could realistically be achieved in the next ten to twenty years ğŸ’¡, which is a far cry from truly sci-fi concepts like time travel or Martians. <br/>![AI News: AGI Timeline Expert Prediction Distribution Comparison Chart](https://source.hubtoday.app/images/2025/12/news_01kckzw6gveaqs57dxqkqyqrx2.avif)<br/>

---

## **AI News Daily Audio Version**

| ğŸ™ï¸ **Xiaoyuzhou** | ğŸ“¹ **Douyin** |
| --- | --- |
| [Laisheng Xiaojiuguan](https://www.xiaoyuzhoufm.com/podcast/683c62b7c1ca9cf575a5030e) | [Self-Media Account](https://www.douyin.com/user/MS4wLjABAAAAwpwqPQlu38sO38VyWgw9ZjDEnN4bMR5j8x111UxpseHR9DpB6-CveI5KRXOWuFwG)|
| ![Xiaojiuguan](https://source.hubtoday.app/logo/f959f7984e9163fc50d3941d79a7f262.md.png) | ![Intelligence Station](https://source.hubtoday.app/logo/7fc30805eeb831e1e2baa3a240683ca3.md.png) |